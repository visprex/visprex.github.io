{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"What is Visprex?","text":""},{"location":"#what-is-visprex","title":"What is Visprex?","text":"<p>Visprex is a lightweight data visualisation platform that helps you speed up your statistical modelling and analytics workflow. The main high-level features include:</p>"},{"location":"#quick","title":"\u23f1\ufe0f Quick","text":"<ul> <li>You can visualise your data in seconds to quickly build an intuition on your dataset</li> <li>No need for referring to specific sytax in your statistical analysis software</li> </ul>"},{"location":"#secure","title":"\ud83d\udd12\ufe0f Secure","text":"<ul> <li>Your data is processed entirely on your browser, which means your data won't be sent anywhere</li> <li>No tracking or analytics software is used for privacy</li> </ul>"},{"location":"#open","title":"\ud83d\udcd6 Open","text":"<ul> <li>Visprex is an open-access software: visprex.com</li> <li>Source code is fully open-source on GitHub: github.com/visprex/visprex</li> </ul>"},{"location":"#who-is-visprex-for","title":"Who is Visprex for?","text":""},{"location":"#students","title":"Students","text":"<p>Visprex is suitable for students who are starting out in their statistical modelling training.</p> <p>There's no need for starting your computing environment on your machine or writing tedious visualisation scripts.</p>"},{"location":"#data-scientists","title":"Data Scientists","text":"<p>Visprex is also suitable for data scientists who would like to quickly inspect their tabular data for analytical purposes, without worrying about privacy or PII as no data is sent outside of your browser.</p>"},{"location":"features/correlation/","title":"Check correlations between features","text":"<p>Correlation Matrix is an useful tool which provides an overview of correlations between features.</p> <p>Note that categorical features are greyed out.</p> <p>In the <code>Correlation Matrix</code> tab, you can see a <code>N-by-N</code> grid of features where <code>N</code> is the number of features in your dataset.</p> <ul> <li>Positive correlation is indicated in warm colous, which approximates red as it approaches 1</li> <li>Negative correlation is indicated in cold colous, which approximates purple as it approaches -1</li> <li>When there is no strong correlation between two features (around 0), the colour gets closer to white</li> </ul>"},{"location":"features/correlation/#positive-correlations","title":"Positive Correlations","text":"<p>With the Iris dataset, for example, you can easily see that the <code>PetalLengthCm</code> and <code>SepalLengthCm</code> features are positively correlated, meaning that the larger the sepal, the larger the petal.</p> <p></p>"},{"location":"features/correlation/#negative-correlations","title":"Negative Correlations","text":"<p>On the other hand, with the <code>world-dataset-2023.csv</code> dataset, you can see that <code>infant_mortality_rate</code> and <code>life_exp_at_birth</code> has a negative correlation of -0.49, meaning that the higher the infant mortality rate, the lower the life expectancy.</p> <p></p>"},{"location":"features/correlation/#removing-colinear-features","title":"Removing colinear features","text":"<p>Correlation matrix can be useful for removing features that are perfectly/extremly highly correlated.</p> <p>For instance, in the <code>world-dataset-2023.csv</code>, there are two measurements called <code>birth rate</code> and <code>fertility rate</code>, with a correlation of 0.98. To simply the linear regression model, one can consider dropping one over the other.</p> <p></p>"},{"location":"features/datasets/","title":"Load your dataset","text":"<p>To get started on your visualisations, you should first see the <code>Datasets</code> tab on visprex.com.</p> <p>For demonstration purposes, you can also choose from publicly available example datasets.</p>"},{"location":"features/datasets/#data-format","title":"Data format","text":"<p>Visprex currently only supports CSV files. Your CSV file should be delimited by commas, and the end of each row should be followed by a new line.</p> <p>First line of the file should have a header which indicates the names of columns (your features).</p>"},{"location":"features/datasets/#data-types","title":"Data types","text":"<p>Your CSV file will be automatically parsed as one of two data types.</p> <ul> <li><code>Numerical</code>:  integers and floats (e.g <code>100</code>, <code>3.14</code>)</li> <li><code>Categorical</code>: string values (e.g <code>\"male\"</code>, <code>\"autumn\"</code>)</li> </ul> <p>Once your data is loaded, this information is shown in the botton part of the <code>Datasets</code> tab, where each column is assigned an index in order of appearance in the first line of your CSV file along with their inferred data type.</p>"},{"location":"features/datasets/#load-your-csv-file","title":"Load your CSV file","text":"<p>Click on <code>Click to load your CSV file</code> and select your CSV file from your local machine.</p> <p></p>"},{"location":"features/datasets/#data-size","title":"Data size","text":"<p>Once your dataset is successfully loaded, it will show <code>Size:</code> field which indicates how many rows and columns your CSV file has</p>"},{"location":"features/datasets/#reference","title":"Reference","text":"<p>If you use an example dataset shown below the data loader, you can see the reference with a link to the description of the original data.</p>"},{"location":"features/datasets/#data-schema","title":"Data schema","text":"<p>Each column will be assigned an index in order of appearance in the first line of your CSV file. <code>Feature</code> is the name of the column and <code>DataType</code> is the inferred data type for the corresponding column. For the <code>iris.csv</code> example dataset. The dataset metadata is shown as follows.</p> <p></p>"},{"location":"features/histogram/","title":"Understand feature distributions","text":"<p>Histograms are useful for visually inspecting feature distributions, and especially to check if it follows a normal (Gaussian) distribution.</p> <p>Normal distributions provide several useful properties for statistical modelling and is one of the key assumptions of linear regression.</p>"},{"location":"features/histogram/#selecting-a-feature","title":"Selecting a feature","text":"<p>Once you load a dataset in the <code>Datasets</code> tab. You can start visualising the distribution of your features by moving on to the <code>Histogram</code> tab. Following from the Datasets tutorial, we use the Iris dataset as an example.</p>"},{"location":"features/histogram/#numerical-features","title":"Numerical features","text":"<p>When you select a <code>Numerical</code> feature, values are counted and put into small intervals (bins).</p> <p>Visually, this means that you can use the X-axis to see where those intervals fall and the Y-axis indicates the count of data points within each bin. For instance, if a bin for values between <code>1.4</code> and <code>1.6</code> has a count of 26, then there were 26 data points which fall into the range <code>[1.4, 1.6)</code>.</p> <p>This example is for the <code>PetalLengthCm</code> feature from the Iris dataset, which measures a flower's petal length in centimeters.</p> <p></p>"},{"location":"features/histogram/#categorical-features","title":"Categorical features","text":"<p>When you select a <code>Categorical</code> feature, value counts are exact and the Y-axis shows how many data points had the exact values shown on the X-axis.</p> <p>From the Iris dataset, the histogram for the <code>Species</code> feature shows how many data points correspond to each species. In this example, you can see that each species is represented equally in this dataset.</p> <p></p>"},{"location":"features/histogram/#feature-transformation","title":"Feature Transformation","text":""},{"location":"features/histogram/#log-transformation-methods","title":"Log transformation methods","text":"<p>Visprex provides two feature transformations out-of-the-box, log10 and and natural log. You can see this in the <code>f(x)</code> section below the list of features.</p> <ul> <li><code>x</code>: Default value. No transformation.</li> <li><code>log10(x)</code>: Logarithmic trasformation with base 10.</li> <li><code>ln(x)</code>: Logarithmic transformation with base e.</li> </ul>"},{"location":"features/histogram/#when-is-log-transformation-useful","title":"When is log transformation useful?","text":"<p>Log transformation is useful when the distribution of your selected feature is heavily skewed to either side.</p> <p>For example, most distributions around money (income, house properties, GDP) tends to have a skewed distribution where a small group of data points show extremely high values.</p> <p>Choose <code>world-dataset-2023.csv</code> from example datasets.</p> <p></p> <p>Click on <code>Histogram</code> tab and select the <code>GDP</code> feature. We can see that the distribution is heavily skewed to the right where countries with higest GDP values lie on the far right side of the histrogram.</p> <p></p> <p>Click on <code>log10(x)</code> to transform the values to the base 10 logarithmic scale, then you can see that the distribution now closely approximates the normal distribution.</p> <p>Given that this value is denominated by the US Dollars and the base is 10, you can now read the bins on this histogram as the number of countries that fall into the range between <code>10^(x)</code> and <code>10^(x+d)</code>, where <code>d</code> is the difference between the start of the interval and the end of the interval on the histogram.</p> <p></p>"},{"location":"features/scatterplot/","title":"Visualise linear relationships","text":"<p>Scatterplot is an effective tool for visualising the relationship between two variables. </p>"},{"location":"features/scatterplot/#selecting-features","title":"Selecting features","text":"<p>It is common to plot the dependent variable (the variable you want to model) on the Y-axis and the independent variables (the variables that you want to study the effects of) on the X-axis.</p> <p>Note that only <code>Numerical</code> features can be selected in scatter plots, and for each <code>Numerical</code> feature, we also have feature transformations explained in the Feature Tranformation section in the the previous tutorial.</p> <p>You can also hover over individual data point to see the actual feature values.</p>"},{"location":"features/scatterplot/#visualising-linear-relationships","title":"Visualising linear relationships","text":"<p>Using the <code>world-dataset-2023.csv</code> from example datasets, let us visualise how fertility rate (X-axis) is related to life expectancy at birth (Y-axis).</p> <p>One can easily infer that there is a linear trend with a downward slope, meaning that the higher the fertility rate (more children are born), the lower the life expectancy. This is an example of clear linear trends between two variables.</p> <p></p>"},{"location":"features/scatterplot/#visualising-log-linear-relationships","title":"Visualising log-linear relationships","text":"<p>Let us now try to visualise the relationship between population on X-axis and GDP on Y-axis with the same <code>world-dataset-2023.csv</code> dataset.</p> <p>Since those two variables are heavily skewed to the right, meaning that some countries have very high values, the it is not trvial to draw a straight line between those dots.</p> <p></p> <p>However, once you apply log transformations, a much cleaner linear relationship appears between these two variables. This is a good example of log-linear relationship, where the log of dependent variable is partially explained by the log of an independent variable.</p> <p></p>"},{"location":"features/scatterplot/#filters","title":"Filters","text":"<p>Filters provide a way to slice your dataset from different angles, using both categorial and numerical features. There are 3 fields to specify for adding a filter</p> <ul> <li>Feature: which feature to filter on</li> <li>Operator: which operator to filter with<ul> <li>for <code>Categorical</code> features, equality (<code>=</code>) and inequality (<code>!=</code>) are supported</li> <li>for <code>Numerical</code> features, less than (<code>&lt;</code>), less than or equal to (<code>&lt;=</code>), greater than (<code>&gt;</code>), greater than or equal to (<code>&gt;=</code>) are also supported</li> </ul> </li> <li>Value: value to compare against</li> </ul> <p>Click on the plus icon to add the filter, which shows up directly below.</p>"},{"location":"features/scatterplot/#controlling-for-other-variables","title":"Controlling for other variables","text":"<p>While scatter plots give you a good sense of how two variables are distributed, it only provides a simplified picture of the overall distribution as it disreagrds the variance in other features and hence their explanatory power for the dependent variable.</p> <p>You can use the filters functionality to set a filtering condition to be applied for all the data points, which means that only the data points that satisfy those conditions will show up in the scatter plot.</p> <p></p> <p>After applying for the filter for <code>Species = \"iris-setosa\"</code>, one can see a linear trend within the species which was not obvious when all the data points were included.</p> <p></p>"},{"location":"features/scatterplot/#visualising-a-subsection-of-your-dataset","title":"Visualising a subsection of your dataset","text":"<p>In other cases, filters could be a useful tool if you would like to focus on a specific subgroup of your dataset.</p> <p>For example, using the <code>nba-2023-24.csv</code> dataset, one can plot the relationship between the NBA players' minutes played (<code>MP</code>) and the field goal made (<code>FG</code>), specifically for those who played for New York Knicks (<code>NYK</code>) as follows.</p> <p></p>"}]}